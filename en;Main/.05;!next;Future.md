---
description: "My future plans."
long_title: "My Future Plans - Zhifeng"
---

# Thank you for visiting this page

I'm **Zhifeng Wang**, currently an incoming senior year undergraduate student majoring in Information Science + Data Science at the School of Information Science at the University of Illinois Urbana Champaign.

## Interest

I'm interested in AI in games. More precisely, I'm interested in how AI learns from its game experiences, how AI heuristics work on pruning the search tree, and how AI heuristics change according to game experiences. I think this problem also applies to the human decision-making process. For example, if I fail or manage to do something, how will this information change my future decisions in similar cases and not that similar cases?

In my understanding, for reinforcement learning, when we receive a reward, it's natural to change or alter the direct behaviors before receiving that reward. If a game only consists of 1000 possible states, we can surely hard-code all the states and probabilities of choosing actions and update them easily according to rewards. But, since we can't practically store a table of all possible scenarios for large games like Connect Four, Chess, Go, and the real world, we need to use some other data structures to "store" the heuristics. In this case, I think how we should update the heuristics data structure can be really tricky. Different states that should have different optimal moves might linked to one parameter, which might be blocking the learning process.

I think this is also an interesting real world problem to think about. For example, if I got a bad score in English tests, do I need to change my math exam preparing behavior?

I want to study how different models might perform differently when learning game heuristics. For example, how might a Convolutional Neural Network's heuristics learning, the ability to induce and apply one experience to multiple future possible cases, differ from a Large Language Model's.

## Previous Works

I was working on visualizing graphs for game-tree visualization and solving the Connect Four game on the default board of width seven and height six. By solving the Connect Four game, we can have all the optimal actions of every state. Maybe we can use that to study the performance of different algorithms.

```con4_graph
{
    "load": ["/src/assets/c4w7h6.len5.20240803.gamegraph.json"],
    "following_actions_string": "3333",
    "api_url": "http://www.zf-w.space/api/c4w7h6/solve",
    "camera_param": {
        "z": 0.8
    },
    "orbit_ctrl_param": {
        "auto_rotate_speed": 0.1
    }
}
```

The above visualization is the Connect Four game graph visualization of states within several moves from the empty board root state.

With the visualization and calculated game results, we might be able to dive deeper into how AI models work on solving games or, more generally, decision-making.
