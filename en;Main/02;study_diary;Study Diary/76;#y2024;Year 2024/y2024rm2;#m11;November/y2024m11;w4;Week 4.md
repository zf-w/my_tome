---
description: "This page is Zhifeng's Study Diary of Week 4, November 2024."
long_title: "Week 4 - Nov 2024 - Study Diary - Zhifeng"
---

# Wednesday, Nov. 27th

## _Understanding Written Problem Instructions_

> APA: Hayes, J. R., & Simon, H. A. (1974). Understanding written problem instructions. Knowledge and cognition, 167-200.

### Tea Ceremony

It's interesting to see that the game of "Tower of Hanoi", or say the state space, can be disguised in different words. I wonder how different initial heuristics might be triggered at the beginning of trying to solve the game. For example, if the game was delivered in the "Tea ceremony" context, the participants might be taking some level of daily understanding of relationship between people into the initial understanding and heuristic on solving the puzzle compared to the plain game of "Tower of Hanoi".

### Discussion of Understanding

> If our main interest lay in artificial intelligence, then we would want the UNDERSTAND program to understand in the deepest, most efficient, most flexible way possible. (p.197)

That's one of the major concerns for my Connect Four study. What's the most efficient way to classify all legal Connect Four boards into seven types of boards representing the optimal moves or 43-ish types of boards representing the best possible results? For the board size of width 6 and height 6, a simple strategy always leads to drawing, but are there any systematic ways to find such a thing for any board size of Connect Four or any arbitrary game?

For example, if the "Tower of Hanoi" is delivered using a huge graph of valid states and transitions, are there any systematic ways to find that the disk representation of the game is the most efficient or "intuitive for human" way for us to find valid moves and solutions.

> Computers are notoriously hard to program, and humans almost as notoriously hard to educate.

I would say the first one might be a lot easier. Even though computers are very complicated, they are still white boxes, I guess. Plus, you can always reboot them.

### Reflections

I guess it would be impossible for people to use only "black box" testing to determine whether a computer program or a person's understanding or solution on a thing with infinite inputs is correct. Maybe, for example, we can't make sure a program or a person can sum two numbers correctly with only "black box" testing. There always might be a "backdoor-ish" error on some magic numbers. Sometimes, the overflow issue of using a fixed number of bits to represent integers can truly confuse and trip off students like me, at least at the beginning.

### Typo

I think there is a "HEURISTIC OMPILER" on page 176. Not sure if that's a typo or not...

# Friday, Nov. 29th

## _CFlow: Supporting Semantic Flow Analysis of Studentsâ€™ Code in Programming Problems at Scale_

> Zhang, A. G., Tang, X., Oney, S., & Chen, Y. (2024, July). CFlow: Supporting Semantic Flow Analysis of Students' Code in Programming Problems at Scale. In Proceedings of the Eleventh ACM Conference on Learning@ Scale (pp. 188-199).

We can view the intellectual activity of coding in different ways. I wonder if it's also possible to view coding or transforming math equations as a process of finding solutions in the state space of code pieces or math equations.

Viewing codes as a linear structure of lines might be helpful in terms of using clustering algorithms of strings(?) to group different implementations and misconceptions together in order to help the instructors find the, maybe, say, weak spots in their lectures and teaching materials.

As Hayes and Simon mentioned, I would say the instructors are trying to identify the "deepest, most efficient," the weak spots that explain the most misconceptions, as mentioned in another literature, "super misconception."

How might a system or visualization be able to identify those? I think that might an interesting research question to dig in.
