---
description: "二〇二五年十二月"
long_title: "二〇二五年十二月 - 学习日记 - 之枫"
---

# 学习日记

# 礼拜二, 十二月九日

我很感激 Jurasic Grill 的员工同意我用我自己的饭盒去打包带走汉堡. 那位员工是一个很细心的人. 他发现我的饭盒底下有一些残留的水珠, 然后他先用纸巾擦干净再把汉堡放进去. 这大概是为了包装汉堡的口味吧, 我想确实底部有一些水会影响汉堡的口感.

# 礼拜一, 十二月八日

今天主要是写完了 CS423 的最后一篇文献阅读, 尝试了 CS421 的 WA11 Hoare Logic 并且还差一份把附加分拿齐全, 然后我最后尝试改了一下 CS423 MP3 的内容.

# 礼拜五, 十二月五日

## CS440 MP11 Reinforcement Learning

我花了几乎半上午加下午的时间去完成了最后的 Machine Project 作业. 我很感恩我能够完成这个作业并学到知识.

一开始我遇到的困难是 N table 和 Q table 的 update 过程不正确. 我添加了一些在终端 terminal 中用字符进行打印并可视化游戏地图的函数, 并研究了测试代码的组成. 在这个过程中, 我发现, 因为这一部分是 early checking 的检查, 所以没有让我自己去更新 Q Table 和 N Table, 而是用了固定的 actions, 那我就可以缩小一些仔细检查的范围了. 我发现, 模型确实多访问了一些本不该访问的 state 并少访问了一些本该经过的 state. 经过一些打印的设计和对测试程序的改造, 我终于发现是我在两个奖励的评分一样的时候默认选择大奖励的缘故, 导致把一些环境推导出的 state 生成错了.

第二个困难主要是检查各种内部复制粘贴时产生的小问题, 比如说我写了一部分代码是关于"max"的, 遍历所有的 action 并找出最大的 value, 然后我把它复制到另一个需要找到最大的 action 的部分, 也就是"argmax", 但是忘记更改最大 action 而只是改了 value, 结果导致选出的 action 只有一个.

第三个困难是我一开始以为是训练时才可以改 table, 后来发觉 documentation 只是说训练时需要 explore, 但是 testing 的部分也要改 N 和 Q table.
